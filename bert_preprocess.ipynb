{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow==2.0\n",
    "# !pip install tensorflow_hub\n",
    "# !pip install bert-for-tf2\n",
    "# !pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, LSTM, Embedding, Flatten, Dense, LeakyReLU, Input\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pickle, sys\n",
    "import numpy as np\n",
    "import tensorflow_hub as hub\n",
    "import bert\n",
    "FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, Flatten, Dense, LeakyReLU, Input\n",
    "from tensorflow.python.keras import backend \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for BERT model\n",
    "def get_masks(tokens, max_seq_length):\n",
    "    \"\"\"Mask for padding\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def get_segments(tokens, max_seq_length):\n",
    "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
    "    if len(tokens)>max_seq_length:\n",
    "        raise IndexError(\"Token length more than max seq length!\")\n",
    "    segments = []\n",
    "    current_segment_id = 0\n",
    "    for token in tokens:\n",
    "        segments.append(current_segment_id)\n",
    "        if token == \"[SEP]\":\n",
    "            current_segment_id = 1\n",
    "    return segments + [0] * (max_seq_length - len(tokens))\n",
    "\n",
    "def get_ids(tokens, tokenizer, max_seq_length):\n",
    "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
    "    token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
    "    return input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializations\n",
    "max_seq_length = 128\n",
    "embed_length = 768\n",
    "bert_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\"\n",
    "bert_layer = hub.KerasLayer(bert_url, trainable=True)\n",
    "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = FullTokenizer(vocab_file, do_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_word_ids (InputLayer)     [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_mask (InputLayer)         [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "keras_layer (KerasLayer)        [(None, 768), (None, 109482241   input_word_ids[0][0]             \n",
      "                                                                 input_mask[0][0]                 \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [(None, 768)]        0           keras_layer[0][1]                \n",
      "==================================================================================================\n",
      "Total params: 109,482,241\n",
      "Trainable params: 109,482,240\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the BERT embedder\n",
    "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_mask\")\n",
    "segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"segment_ids\")\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "clf_output = sequence_output[:, 0, :]\n",
    "model = Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=clf_output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test embedder on a simple sentence\n",
    "s = \"This is a nice sentence.\"\n",
    "stokens = tokenizer.tokenize(s)\n",
    "stokens = [\"[CLS]\"] + stokens + [\"[SEP]\"]\n",
    "input_ids = get_ids(stokens, tokenizer, max_seq_length)\n",
    "input_masks = get_masks(stokens, max_seq_length)\n",
    "input_segments = get_segments(stokens, max_seq_length)\n",
    "model.predict([[input_ids],[input_masks],[input_segments]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_row(text):\n",
    "    stokens = tokenizer.tokenize(text)\n",
    "    stokens = [\"[CLS]\"] + stokens + [\"[SEP]\"]\n",
    "    input_ids = get_ids(stokens, tokenizer, max_seq_length)\n",
    "    input_masks = get_masks(stokens, max_seq_length)\n",
    "    input_segments = get_segments(stokens, max_seq_length) \n",
    "    return model.predict([[input_ids],[input_masks],[input_segments]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 768, 1)\n",
      "(100, 768, 1)\n",
      "(150, 768, 1)\n",
      "(200, 768, 1)\n",
      "(250, 768, 1)\n",
      "(300, 768, 1)\n",
      "(350, 768, 1)\n",
      "(400, 768, 1)\n",
      "(450, 768, 1)\n",
      "(500, 768, 1)\n",
      "(550, 768, 1)\n",
      "(600, 768, 1)\n",
      "(650, 768, 1)\n",
      "(700, 768, 1)\n",
      "(750, 768, 1)\n",
      "(800, 768, 1)\n",
      "(850, 768, 1)\n",
      "(900, 768, 1)\n",
      "(950, 768, 1)\n",
      "(1000, 768, 1)\n",
      "(1050, 768, 1)\n",
      "(1100, 768, 1)\n",
      "(1150, 768, 1)\n",
      "(1200, 768, 1)\n",
      "(1250, 768, 1)\n",
      "(1300, 768, 1)\n",
      "(1350, 768, 1)\n",
      "(1400, 768, 1)\n",
      "(1450, 768, 1)\n",
      "(1500, 768, 1)\n",
      "(1550, 768, 1)\n",
      "(1600, 768, 1)\n",
      "(1650, 768, 1)\n",
      "(1700, 768, 1)\n",
      "(1750, 768, 1)\n",
      "(1800, 768, 1)\n",
      "(1850, 768, 1)\n",
      "(1900, 768, 1)\n",
      "(1950, 768, 1)\n",
      "(2000, 768, 1)\n",
      "(2050, 768, 1)\n",
      "(2100, 768, 1)\n",
      "(2150, 768, 1)\n",
      "(2200, 768, 1)\n",
      "(2250, 768, 1)\n",
      "(2300, 768, 1)\n",
      "(2350, 768, 1)\n",
      "(2400, 768, 1)\n",
      "(2450, 768, 1)\n",
      "(2500, 768, 1)\n",
      "(2550, 768, 1)\n",
      "(2600, 768, 1)\n",
      "(2650, 768, 1)\n",
      "(2700, 768, 1)\n",
      "(2750, 768, 1)\n",
      "(2800, 768, 1)\n",
      "(2850, 768, 1)\n",
      "(2900, 768, 1)\n",
      "(2950, 768, 1)\n",
      "(3000, 768, 1)\n",
      "(3050, 768, 1)\n",
      "(3100, 768, 1)\n",
      "(3150, 768, 1)\n",
      "(3200, 768, 1)\n",
      "(3250, 768, 1)\n",
      "(3300, 768, 1)\n",
      "(3350, 768, 1)\n",
      "(3400, 768, 1)\n",
      "(3450, 768, 1)\n",
      "(3500, 768, 1)\n",
      "(3550, 768, 1)\n",
      "(3600, 768, 1)\n",
      "(3650, 768, 1)\n",
      "(3700, 768, 1)\n",
      "(3750, 768, 1)\n",
      "(3800, 768, 1)\n",
      "(3850, 768, 1)\n",
      "(3900, 768, 1)\n",
      "(3950, 768, 1)\n",
      "(4000, 768, 1)\n",
      "(4050, 768, 1)\n",
      "(4100, 768, 1)\n",
      "(4150, 768, 1)\n",
      "(4200, 768, 1)\n",
      "(4250, 768, 1)\n",
      "(4300, 768, 1)\n",
      "(4350, 768, 1)\n",
      "(4400, 768, 1)\n",
      "(4450, 768, 1)\n",
      "(4500, 768, 1)\n",
      "(4550, 768, 1)\n",
      "(4600, 768, 1)\n",
      "(4650, 768, 1)\n",
      "(4700, 768, 1)\n",
      "(4750, 768, 1)\n",
      "(4800, 768, 1)\n",
      "(4850, 768, 1)\n",
      "(4900, 768, 1)\n",
      "(4950, 768, 1)\n",
      "(5000, 768, 1)\n",
      "(5050, 768, 1)\n",
      "(5100, 768, 1)\n",
      "(5150, 768, 1)\n",
      "(5200, 768, 1)\n",
      "(5250, 768, 1)\n",
      "(5300, 768, 1)\n",
      "(5350, 768, 1)\n",
      "(5400, 768, 1)\n",
      "(5450, 768, 1)\n",
      "(5500, 768, 1)\n",
      "(5550, 768, 1)\n",
      "(5600, 768, 1)\n",
      "(5650, 768, 1)\n",
      "(5700, 768, 1)\n",
      "(5750, 768, 1)\n",
      "(5800, 768, 1)\n",
      "(5850, 768, 1)\n",
      "(5900, 768, 1)\n",
      "(5950, 768, 1)\n",
      "(6000, 768, 1)\n",
      "(6050, 768, 1)\n",
      "(6100, 768, 1)\n",
      "(6150, 768, 1)\n",
      "(6200, 768, 1)\n",
      "(6250, 768, 1)\n",
      "(6300, 768, 1)\n",
      "(6350, 768, 1)\n",
      "(6400, 768, 1)\n",
      "(6450, 768, 1)\n",
      "(6500, 768, 1)\n",
      "(6550, 768, 1)\n",
      "(6600, 768, 1)\n",
      "(6650, 768, 1)\n",
      "(6700, 768, 1)\n",
      "(6750, 768, 1)\n",
      "(6800, 768, 1)\n",
      "(6850, 768, 1)\n",
      "(6900, 768, 1)\n",
      "(6950, 768, 1)\n",
      "(7000, 768, 1)\n",
      "(7050, 768, 1)\n",
      "(7100, 768, 1)\n",
      "(7150, 768, 1)\n",
      "(7200, 768, 1)\n",
      "(7250, 768, 1)\n",
      "(7300, 768, 1)\n",
      "(7350, 768, 1)\n",
      "(7400, 768, 1)\n",
      "(7450, 768, 1)\n",
      "(7500, 768, 1)\n",
      "(7550, 768, 1)\n",
      "(7600, 768, 1)\n",
      "(7613, 768, 1)\n"
     ]
    }
   ],
   "source": [
    "# embed the whole data, but do it in chunks. The whole thing may not fit into memory all at once.\n",
    "chunksize = 50\n",
    "X = None\n",
    "for i, chunk in enumerate(pd.read_csv(\"train.csv\", usecols=['text'], chunksize=chunksize)):\n",
    "    # if i>10:\n",
    "    #    break\n",
    "    if type(X)==type(None):\n",
    "        X = np.vstack(chunk.text.apply(embed_row).values)\n",
    "        X = np.expand_dims(X, axis=2)\n",
    "    else:\n",
    "        X_temp = np.vstack(chunk.text.apply(embed_row).values)\n",
    "        X_temp = np.expand_dims(X_temp, axis=2)\n",
    "        X = np.vstack((X, X_temp))\n",
    "    print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X.p', 'wb') as handle:\n",
    "    pickle.dump(X, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-fibber]",
   "language": "python",
   "name": "conda-env-.conda-fibber-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
